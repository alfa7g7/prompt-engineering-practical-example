======================================================================
### TEST 1: Zero-Shot Prompting
======================================================================

----------------------------------------------------------------------
#### PROMPT USADO:
----------------------------------------------------------------------
[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?
[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT
... (contenido completo de chats.txt) ...
[jane_d] 2023-06-24T16:30:11+00:00: It's 3344556. Thanks for your help!


Remove personally identifiable information, only show the date,
and replace all swear words with ""

----------------------------------------------------------------------
#### OUTPUT RECIBIDO:
----------------------------------------------------------------------
 2023-07-24T10:02:23+00:00 : What can I help you with?
 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT
... (casi todas las l铆neas empezaban con ) ...

----------------------------------------------------------------------
#### CONCLUSIONES:
----------------------------------------------------------------------
- **Fallo casi total.** El modelo no fue capaz de seguir instrucciones complejas presentadas en un solo p谩rrafo.
- No elimin贸 nombres, n煤meros de orden ni emails.
- No limpi贸 el formato de la fecha.
- Malinterpret贸 la instrucci贸n de "reemplazar groser铆as" y a帽adi贸 un emoji  al principio de casi todas las l铆neas.
- La 煤nica instrucci贸n que sigui贸 correctamente fue reemplazar la palabra "Blast!".
- **Veredicto:** Un prompt "zero-shot" es insuficiente para tareas con m煤ltiples restricciones y que requieren inferencia de contexto (saber qu茅 es un nombre o un n煤mero de orden sin que se le diga expl铆citamente).

======================================================================
### TEST 2: Few-Shot Prompting + Delimiters
======================================================================

----------------------------------------------------------------------
#### PROMPT USADO (extracto del `settings.toml`):
----------------------------------------------------------------------
instruction_prompt = """Remove personally identifiable information
from >>>>>CONTENT<<<<<, only show the date,
and replace all swear words with ""

#### START EXAMPLES

------ Example Inputs ------
[support_tom] 2023-07-24...
... (dos ejemplos completos con input y output) ...
------ Example Outputs ------
...
[Customer] 2023-06-15 : It's ********. Thanks for helping me out!

#### END EXAMPLES
"""

----------------------------------------------------------------------
#### OUTPUT RECIBIDO:
----------------------------------------------------------------------
[Agent] 2023-05-05 : Hi, how can I help you today?
[Customer] 2023-05-05 : MY BLASTED ORDER STILL HASN'T ARRIVED AND IT'S BEEN A WEEK!!!
... (resto del output correcto pero incompleto) ...

----------------------------------------------------------------------
#### CONCLUSIONES:
----------------------------------------------------------------------
- **Mejora dr谩stica.** El modelo ahora entiende el formato de salida deseado.
- **xitos:**
    - Sanitiza la mayor铆a de nombres y n煤meros de orden.
    - Acorta correctamente el formato de la fecha.
    - Cambia los roles a [Agent] y [Customer].
- **Fallos:**
    - Se salt贸 las primeras conversaciones del archivo.
    - Olvid贸 reemplazar la groser铆a "BLASTED".
    - No sanitiz贸 informaci贸n que no estaba en los ejemplos (como c贸digos de cup贸n).
- **Veredicto:** Los ejemplos y los delimitadores son t茅cnicas muy efectivas para guiar al modelo, pero el prompt a煤n no es lo suficientemente robusto para generalizar a casos no vistos o para recordar todas las instrucciones a la vez. 

======================================================================
### TEST 3: Numbered Steps Prompt on New Data
======================================================================

----------------------------------------------------------------------
#### PROMPT USADO (extracto del `settings.toml`):
----------------------------------------------------------------------
instruction_prompt = """
Sanitize the text provided in >>>CONTENT<<< in multiple steps:

1. Replace personally identifiable information (customer names, agent names, email addresses, order numbers) with `********`
2. Replace names in [] with "Agent" and "Client", respectively
3. Replace the date-time information to only show the date in the format YYYY-mm-dd
4. Replace all swear words with the following emoji: ""

#### START EXAMPLES
... (los mismos dos ejemplos) ...
#### END EXAMPLES
"""

----------------------------------------------------------------------
#### OUTPUT RECIBIDO (con `testing-chats.txt`):
----------------------------------------------------------------------
[Agent] 2023-07-15 : Hello! What can I help you with today?
[Client] 2023-07-15 : Hey, my promo code isn't applying the discount in my cart.
[Agent] 2023-07-15 : My apologies for the trouble, ********. Could you tell me the promo code you're trying to use?
[Client] 2023-07-15 : It's "SAVE20".
... (resto del output, mucho m谩s correcto) ...

----------------------------------------------------------------------
#### CONCLUSIONES:
----------------------------------------------------------------------
- **xito rotundo.** Este es el mejor resultado hasta ahora.
- **Generalizaci贸n:** El modelo fue capaz de aplicar las reglas a datos completamente nuevos que no estaban en los ejemplos.
- **xitos gracias a los pasos expl铆citos:**
    - Sanitiz贸 nuevos nombres ("Peter") y nueva informaci贸n sensible ("iPhone 11").
    - Sanitiz贸 nuevas groser铆as ("darn", "friggin") gracias a la instrucci贸n "reemplaza TODAS las groser铆as".
- **Fallo menor y esperado:** No sanitiz贸 el c贸digo de cup贸n "SAVE20" porque no se lo pedimos expl铆citamente en la lista de "informaci贸n personal identificable". El modelo hizo exactamente lo que se le pidi贸.
- **Veredicto:** Dar instrucciones como una lista de pasos expl铆citos es una t茅cnica de prompt engineering muy poderosa para tareas complejas y para mejorar la generalizaci贸n del modelo. 

======================================================================
### TEST 4: Chain-of-Thought Prompting on Chat Model
======================================================================

----------------------------------------------------------------------
#### PROMPT USADO (extracto del `settings.toml` y `app.py`):
----------------------------------------------------------------------
El sistema ahora env铆a una secuencia de mensajes que simulan una conversaci贸n, incluyendo ejemplos de PENSAMIENTO y RESPUESTA antes de la petici贸n real.

- messages = [
-     {"role": "system", "content": role_prompt},
-     {"role": "user", "content": negative_example},
-     {"role": "system", "content": negative_reasoning},   <-- 隆El modelo ve el razonamiento!
-     {"role": "assistant", "content": negative_output},
-     ... (y lo mismo para el ejemplo positivo) ...
- ]

----------------------------------------------------------------------
#### OUTPUT RECIBIDO (con `testing-chats.txt`):
----------------------------------------------------------------------
{
  "sentiment": "negative",
  "sanitized_conversation": [
    "[Agent] 2023-07-15 : Hello! What can I help you with today?",
    "[Client] 2023-07-15 : , my promo code isn't applying the discount in my cart.",
    ... (output perfecto y consistente) ...
  ]
}

----------------------------------------------------------------------
#### CONCLUSIONES:
----------------------------------------------------------------------
- **Resultado perfecto y consistente.** Se han solucionado todos los problemas anteriores.
- **xitos gracias al Chain-of-Thought:**
    - El modelo ahora reemplaza TODAS las groser铆as de forma fiable.
    - El formato de salida (incluyendo los corchetes en `[Agent]`) es consistente con los ejemplos.
    - Se cumplen todas las instrucciones (sanitizaci贸n, sentimiento, formato JSON) sin "olvidar" ninguna.
- **Veredicto:** La t茅cnica de Chain-of-Thought es la m谩s poderosa para tareas complejas que requieren m煤ltiples pasos de razonamiento. Al mostrarle al modelo CMO pensar, no solo QU hacer, se logran los resultados de mayor calidad y fiabilidad. Es el estado del arte para el prompt engineering complejo. 